{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:04.100811Z",
     "iopub.status.busy": "2020-09-12T21:51:04.100117Z",
     "iopub.status.idle": "2020-09-12T21:51:05.368032Z",
     "shell.execute_reply": "2020-09-12T21:51:05.366844Z"
    },
    "papermill": {
     "duration": 1.289008,
     "end_time": "2020-09-12T21:51:05.368165",
     "exception": false,
     "start_time": "2020-09-12T21:51:04.079157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Installing EfficientNet model without internet due to competition requisites\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path = [\n",
    "    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n",
    "] + sys.path\n",
    "\n",
    "import torch\n",
    "os.listdir(\"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master\")\n",
    "\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "#!pip install efficientnet_pytorch torchtoolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:05.406713Z",
     "iopub.status.busy": "2020-09-12T21:51:05.406005Z",
     "iopub.status.idle": "2020-09-12T21:51:06.746428Z",
     "shell.execute_reply": "2020-09-12T21:51:06.745355Z"
    },
    "papermill": {
     "duration": 1.364675,
     "end_time": "2020-09-12T21:51:06.746550",
     "exception": false,
     "start_time": "2020-09-12T21:51:05.381875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "# Imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import skimage.io\n",
    "#from csv_loader import load_csv\n",
    "\n",
    "# Tiff visualisation imports and downloads\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "# For re-importing python modules\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:07.120262Z",
     "iopub.status.busy": "2020-09-12T21:51:07.119540Z",
     "iopub.status.idle": "2020-09-12T21:51:07.124153Z",
     "shell.execute_reply": "2020-09-12T21:51:07.124639Z"
    },
    "papermill": {
     "duration": 0.36376,
     "end_time": "2020-09-12T21:51:07.124798",
     "exception": false,
     "start_time": "2020-09-12T21:51:06.761038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:07.172954Z",
     "iopub.status.busy": "2020-09-12T21:51:07.162478Z",
     "iopub.status.idle": "2020-09-12T21:51:07.185533Z",
     "shell.execute_reply": "2020-09-12T21:51:07.184964Z"
    },
    "papermill": {
     "duration": 0.045536,
     "end_time": "2020-09-12T21:51:07.185652",
     "exception": false,
     "start_time": "2020-09-12T21:51:07.140116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These image augmentation functions have already been defined in another notebook.\n",
    "# Using these functions to pre-process test images before running them through the model.\n",
    "\n",
    "def compute_statistics(img):\n",
    "    #img = skimage.io.MultiImage(image)[2]\n",
    "    width, height = img.shape[0], img.shape[1]\n",
    "    num_pixels = width * height\n",
    "    \n",
    "    num_white_pixels = 0\n",
    "    green_values_img = 0\n",
    "    blue_values_img = 0\n",
    "    \n",
    "    pixelsum=np.sum(img,axis=-1)\n",
    "    num_white_pixels = int((pixelsum>620).sum())\n",
    "    \n",
    "    green_values_img=np.sum(img[:,:,1])\n",
    "    blue_values_img=np.sum(img[:,:,2])\n",
    "    \n",
    "    ratio_white_pixels = num_white_pixels / num_pixels\n",
    "    green_concentration = green_values_img / num_pixels\n",
    "    blue_concentration = blue_values_img / num_pixels\n",
    "    \n",
    "    return ratio_white_pixels, green_concentration, blue_concentration\n",
    "\n",
    "\n",
    "def select_k_best_regions(regions, k=16):\n",
    "    best_regions = [x for x in regions if x[3] > 0 and x[4] > 0]\n",
    "    k_best_regions = sorted(best_regions, key=lambda tup: tup[2])[:k]\n",
    "    \n",
    "    return k_best_regions\n",
    "\n",
    "\n",
    "def get_k_best_regions(coordinates, image, window_size=512):\n",
    "    regions = {}\n",
    "    for i, tup in enumerate(coordinates):\n",
    "        x, y = tup[0], tup[1]\n",
    "        regions[i] = image[x : x+window_size, y : y+window_size, :]\n",
    "    \n",
    "    return regions\n",
    "\n",
    "\n",
    "def generate_patches(image, window_size=200, stride=135, k=20):\n",
    "    #image = skimage.io.MultiImage(slide_path)[1]\n",
    "    image = np.array(image)\n",
    "    \n",
    "    max_width, max_height = image.shape[0], image.shape[1]\n",
    "    regions_container = []\n",
    "    i = 0\n",
    "    \n",
    "    while window_size + stride*i <= max_height:\n",
    "        j = 0\n",
    "        \n",
    "        while window_size + stride*j <= max_width:            \n",
    "            x_top_left_pixel = j * stride\n",
    "            y_top_left_pixel = i * stride\n",
    "            \n",
    "            patch = image[\n",
    "                x_top_left_pixel : x_top_left_pixel + window_size,\n",
    "                y_top_left_pixel : y_top_left_pixel + window_size,\n",
    "                :]\n",
    "            \n",
    "            ratio_white_pixels, green_concentration, blue_concentration = compute_statistics(patch)\n",
    "            \n",
    "            region_tuple = (x_top_left_pixel, y_top_left_pixel, ratio_white_pixels, green_concentration, blue_concentration)\n",
    "            regions_container.append(region_tuple)\n",
    "            \n",
    "            j += 1\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    k_best_region_coordinates = select_k_best_regions(regions_container, k=k)\n",
    "    k_best_regions = get_k_best_regions(k_best_region_coordinates, image, window_size)\n",
    "    #excess_overlap_removed = remove_overlaps(k_best_regions, k_sample=k, k_final=16)\n",
    "    \n",
    "           \n",
    "    return image, k_best_region_coordinates, k_best_regions #, excess_overlap_removed\n",
    "\n",
    "\n",
    "def display_images(regions, title):\n",
    "    fig, ax = plt.subplots(5, 5, figsize=(20, 20))\n",
    "    \n",
    "    for i, region in regions.items():\n",
    "        ax[i//5, i%5].imshow(region)\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "\n",
    "    \n",
    "def glue_to_one_picture(image_patches, window_size=200, k=16):\n",
    "    side = int(np.sqrt(k))\n",
    "    image = np.zeros((side*window_size, side*window_size, 3), dtype=np.int16)\n",
    "        \n",
    "    for i, patch in image_patches.items():\n",
    "        x = i // side\n",
    "        y = i % side\n",
    "        image[\n",
    "            x * window_size : (x+1) * window_size,\n",
    "            y * window_size : (y+1) * window_size,\n",
    "            :\n",
    "        ] = patch\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:07.225238Z",
     "iopub.status.busy": "2020-09-12T21:51:07.224405Z",
     "iopub.status.idle": "2020-09-12T21:51:07.228775Z",
     "shell.execute_reply": "2020-09-12T21:51:07.227925Z"
    },
    "papermill": {
     "duration": 0.02941,
     "end_time": "2020-09-12T21:51:07.228887",
     "exception": false,
     "start_time": "2020-09-12T21:51:07.199477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class load_csv(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)# todo remove sample for debug\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image_id = self.annotations.iloc[index, 0]\n",
    "        img_path = os.path.join(self.root_dir, str(image_id) +\".tiff\")\n",
    "        img = skimage.io.MultiImage(img_path)[1]\n",
    "        \n",
    "        image, best_coordinates, best_regions = generate_patches(img, window_size=128, stride=84, k=16)\n",
    "        glued_img = glue_to_one_picture(best_regions, window_size=128, k=16)\n",
    "        \n",
    "        image = torch.from_numpy(glued_img).permute(2,0,1).float()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Image.MAX_IMAGE_PIXELS = None\n",
    "                \n",
    "        #image.transform = transforms.RandomResizedCrop(224)\n",
    "        \n",
    "        #y_label = torch.tensor(int(self.annotations.iloc[index,:]['isup_grade']))\n",
    "        #isup_grade = int(self.annotations.iloc[index,:]['isup_grade'])\n",
    "        \n",
    "        #label = np.zeros(6).astype(np.float32)\n",
    "        #y_label = label[isup_grade] = 1.\n",
    "        #y_label = torch.tensor(y_label)\n",
    "        \n",
    "        self.transform= transforms.Compose([transforms.ToPILImage(),\n",
    "                                            #transforms.Resize((int(1840/2),int(1728/2))), \n",
    "                                            transforms.ToTensor()])\n",
    "                                            #transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                             #      [0.229, 0.224, 0.225])])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return (image, np.array(0))#1840, 1728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:07.263996Z",
     "iopub.status.busy": "2020-09-12T21:51:07.263139Z",
     "iopub.status.idle": "2020-09-12T21:51:12.870573Z",
     "shell.execute_reply": "2020-09-12T21:51:12.871065Z"
    },
    "papermill": {
     "duration": 5.628953,
     "end_time": "2020-09-12T21:51:12.871201",
     "exception": false,
     "start_time": "2020-09-12T21:51:07.242248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=216, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=216, out_features=36, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=36, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading model\n",
    "\n",
    "model = EfficientNet.from_name('efficientnet-b0')\n",
    "model.load_state_dict(torch.load(\"../input/efficientnet-pytorch/efficientnet-b0-08094119.pth\"))\n",
    "model._fc = nn.Sequential(nn.Linear(model._fc.in_features, 216),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(216, 36, bias=True),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(36, 5, bias=True))\n",
    "\n",
    "# Model path\n",
    "model_path = '../input/200912-base-model-w-logits/base_model_w_logits.pth'\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "# Load model parameters\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model._fc.load_state_dict(checkpoint['classifier_state_dict'])\n",
    "\n",
    "# Load other model related components\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:12.911972Z",
     "iopub.status.busy": "2020-09-12T21:51:12.911154Z",
     "iopub.status.idle": "2020-09-12T21:51:13.162713Z",
     "shell.execute_reply": "2020-09-12T21:51:13.161610Z"
    },
    "papermill": {
     "duration": 0.276739,
     "end_time": "2020-09-12T21:51:13.162838",
     "exception": false,
     "start_time": "2020-09-12T21:51:12.886099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For submission\n",
    "submission_test_path = \"/kaggle/input/prostate-cancer-grade-assessment/test_images/\"\n",
    "csv_file_dir = '/kaggle/input/prostate-cancer-grade-assessment/test.csv'\n",
    "\n",
    "pred_y_excel = []\n",
    "submission=None\n",
    "if os.path.exists(submission_test_path):\n",
    "    #print(\"dir found\")\n",
    "    test_df = pd.read_csv(csv_file_dir)\n",
    "    test_data = load_csv(csv_file=csv_file_dir, root_dir=submission_test_path)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "    #model.eval()\n",
    "    for ii2, (inputs2, labels2) in enumerate(test_loader):\n",
    "        inputs2, labels2 = inputs2.to(device), labels2.to(device)\n",
    "    \n",
    "        output2 = model.forward(inputs2)\n",
    "        pred_y2 = output2.sigmoid().sum(1).round().detach()\n",
    "\n",
    "        pred_y_excel.append(int(pred_y2))\n",
    "    #print(\"writing csv\")\n",
    "    #pred_y_excel = [3 for i in range(test_df.shape[0])]\n",
    "    submission = pd.DataFrame({'image_id':test_df.image_id, 'isup_grade':pred_y_excel})\n",
    "    submission.to_csv(\"submission.csv\", sep=\",\", index=False)\n",
    "else:\n",
    "    #print(\"dir not found, building dummy\")\n",
    "    test_df = pd.read_csv(\"/kaggle/input/prostate-cancer-grade-assessment/sample_submission.csv\")\n",
    "#     test_df['isup_grade'] = 0\n",
    "#     fake_submission=test_df[['image_id','isup_grade']]\n",
    "    test_df.to_csv('submission.csv', index=False)\n",
    "    #print('submission saved')\n",
    "    #print(fake_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.014382,
     "end_time": "2020-09-12T21:51:13.193267",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.178885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.014086,
     "end_time": "2020-09-12T21:51:13.221523",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.207437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:13.256711Z",
     "iopub.status.busy": "2020-09-12T21:51:13.254782Z",
     "iopub.status.idle": "2020-09-12T21:51:13.257450Z",
     "shell.execute_reply": "2020-09-12T21:51:13.258039Z"
    },
    "papermill": {
     "duration": 0.02176,
     "end_time": "2020-09-12T21:51:13.258164",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.236404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#file_info = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').copy()\n",
    "#sample_size = 500\n",
    "#submit_list = file_info.sample(sample_size)\n",
    "#submit_list.to_csv(\"sample.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:13.291803Z",
     "iopub.status.busy": "2020-09-12T21:51:13.290964Z",
     "iopub.status.idle": "2020-09-12T21:51:13.293813Z",
     "shell.execute_reply": "2020-09-12T21:51:13.293327Z"
    },
    "papermill": {
     "duration": 0.02093,
     "end_time": "2020-09-12T21:51:13.293913",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.272983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data = load_csv(csv_file='./sample.csv', root_dir='../input/prostate-cancer-grade-assessment/train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:13.328237Z",
     "iopub.status.busy": "2020-09-12T21:51:13.326578Z",
     "iopub.status.idle": "2020-09-12T21:51:13.328947Z",
     "shell.execute_reply": "2020-09-12T21:51:13.329452Z"
    },
    "papermill": {
     "duration": 0.021036,
     "end_time": "2020-09-12T21:51:13.329566",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.308530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:13.364350Z",
     "iopub.status.busy": "2020-09-12T21:51:13.363616Z",
     "iopub.status.idle": "2020-09-12T21:51:13.369186Z",
     "shell.execute_reply": "2020-09-12T21:51:13.368666Z"
    },
    "papermill": {
     "duration": 0.024918,
     "end_time": "2020-09-12T21:51:13.369285",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.344367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef validate_data_function(model, test_loader, criterion):\\n    test_loss = 0\\n    accuracy = 0\\n    \\n    df_test = {'image_id': [],\\n             'label': [],\\n             'y_pred': []}\\n    \\n    for ii, (inputs, labels) in enumerate(test_loader):\\n        \\n        inputs, labels = inputs.to(device), labels.to(device)\\n        \\n        output = model.forward(inputs)\\n        pred_y = output.argmax(dim=1)\\n        \\n        \\n        #ps = torch.exp(output)\\n        #equality = (labels.argmax(dim=1) == output.argmax(dim=1))\\n        equality = (labels == output.argmax(dim=1))\\n        accuracy += equality.type(torch.FloatTensor)\\n        \\n    accuracy = accuracy/len(test_loader)\\n    accuracy.item\\n    return test_loss, accuracy[0], pred_y, labels, df_test\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def validate_data_function(model, test_loader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    df_test = {'image_id': [],\n",
    "             'label': [],\n",
    "             'y_pred': []}\n",
    "    \n",
    "    for ii, (inputs, labels) in enumerate(test_loader):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        output = model.forward(inputs)\n",
    "        pred_y = output.argmax(dim=1)\n",
    "        \n",
    "        \n",
    "        #ps = torch.exp(output)\n",
    "        #equality = (labels.argmax(dim=1) == output.argmax(dim=1))\n",
    "        equality = (labels == output.argmax(dim=1))\n",
    "        accuracy += equality.type(torch.FloatTensor)\n",
    "        \n",
    "    accuracy = accuracy/len(test_loader)\n",
    "    accuracy.item\n",
    "    return test_loss, accuracy[0], pred_y, labels, df_test\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T21:51:13.404317Z",
     "iopub.status.busy": "2020-09-12T21:51:13.403692Z",
     "iopub.status.idle": "2020-09-12T21:51:13.408060Z",
     "shell.execute_reply": "2020-09-12T21:51:13.407508Z"
    },
    "papermill": {
     "duration": 0.022956,
     "end_time": "2020-09-12T21:51:13.408161",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.385205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing the data validator function\n",
    "#model.eval()\n",
    "    \n",
    "#with torch.no_grad():\n",
    "#    test_loss, accuracy, pred_y, labels, df_test = validate_data_function(model, train_loader, criterion)\n",
    "              \n",
    "#print(\"Test Accuracy: {:.2f}%\".format(accuracy))#*100/len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.015369,
     "end_time": "2020-09-12T21:51:13.439344",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.423975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.015253,
     "end_time": "2020-09-12T21:51:13.470255",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.455002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01515,
     "end_time": "2020-09-12T21:51:13.500796",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.485646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01495,
     "end_time": "2020-09-12T21:51:13.531549",
     "exception": false,
     "start_time": "2020-09-12T21:51:13.516599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 14.719366,
   "end_time": "2020-09-12T21:51:14.938365",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-12T21:51:00.218999",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
