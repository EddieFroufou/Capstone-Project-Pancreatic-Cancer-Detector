{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch torchtoolbox","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Imports here\nfrom efficientnet_pytorch import EfficientNet\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport csv\nimport pandas as pd\nimport os\nimport random\nimport math\nimport skimage.io\n#from csv_loader import load_csv\n\n# Tiff visualisation imports and downloads\nimport numpy as np\nimport tifffile as tiff\n\n# For re-importing python modules\nimport importlib\n#importlib.reload(csv_loader.py)\n\n#for quadratic score calculator\nfrom sklearn.metrics import cohen_kappa_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.set_default_tensor_type(torch.cuda.FloatTensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating ability to control how many pictures go into the training sample. For debugging / training purposes\nsample_size = 10000\ndf = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').copy().sample(sample_size)\ndf.to_csv(\"sample.csv\", sep=\",\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class load_csv(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.annotations = pd.read_csv(csv_file)# todo remove sample for debug\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.annotations)\n        \n    \n    def __getitem__(self, index):\n        image_id = self.annotations.iloc[index, 0]\n        img_path = os.path.join(self.root_dir, str(image_id) +\".png\")\n        image = torch.from_numpy(skimage.io.imread(img_path)).permute(2,0,1).float()\n        \n        #y_label = torch.tensor(int(self.annotations.iloc[index,:]['isup_grade']))\n        isup_grade = int(self.annotations.iloc[index,:]['isup_grade'])\n        \n        label = np.zeros(5).astype(np.float32)\n        label[:isup_grade] = 1.\n        \n        \n        self.transform= transforms.Compose([transforms.ToPILImage(),\n                                            transforms.ToTensor()])\n                                            \n        if self.transform:\n            image = self.transform(image)\n        \n        return (image, torch.tensor(label), image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading csv dataset into the dataset loader function load_csv. \ndataset = load_csv(csv_file='sample.csv', root_dir='../input/prostate-cancer-tiles-4x4x128px-downsampling-4x/train_128x4x4_res1/train_128x4x4_res1')\n\n# Creating sample subsets for validation and testing datasets\nsample_size = dataset.annotations.shape[0]\ntrain_ratio = .72\nvalid_ratio = .18\ntest_ratio = 1-(train_ratio + valid_ratio)\ntrain_size = int(train_ratio*sample_size)\nvalid_size = int(valid_ratio*sample_size)\ntest_size = sample_size - train_size - valid_size\n\n# Defining different datasets and respective dataloaders\ntrain_set, valid_set, test_set = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=5, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_set, batch_size=5, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)\nentire_set_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating model and uploading/creating needed training components\nmodel = EfficientNet.from_pretrained('efficientnet-b0', num_classes=5)\nmodel._fc = model._fc = nn.Sequential(nn.Linear(model._fc.in_features, 216),\n                          nn.ReLU(),\n                          nn.Linear(216, 36, bias=True),\n                          nn.ReLU(),\n                          nn.Linear(36, 5, bias=True)\n#                          nn.Sigmoid()\n                                     )\n\n\nif torch.cuda.is_available():\n    model = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testcriterion= nn.BCEWithLogitsLoss(reduction='none')\npred=torch.ones([10, 11], dtype=torch.float32)\ntruth=torch.ones([10, 11], dtype=torch.float32)#torch.full([10, 11], 1.0)\ntestcriterion(pred,truth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate_data_function(model, test_loader, criterion):\n    test_loss = 0\n    accuracy = 0\n    output_list = []\n    preds_list = []\n    dec_list = []\n    target_list = []\n    loss_list = []\n    \n    with torch.no_grad():\n        \n        for ii, (inputs, labels, image_id) in enumerate(test_loader):\n        \n            inputs, labels = inputs.to(device), labels.to(device)\n            output = model.forward(inputs)\n        \n            loss = criterion(output,labels)\n               \n            dec = output.sigmoid().sum(1).detach()\n        \n            output_list.append(output)\n            preds_list.append(dec.round())\n            target_list.append(labels.sum(1))\n            dec_list.append(dec)\n        \n            loss_np = loss.detach().cpu().numpy()\n            loss_list.append(loss_np)        \n        test_loss = np.mean(loss_list)\n        \n        preds_list = torch.cat(preds_list).cpu().numpy()\n        target_list = torch.cat(target_list).cpu().numpy()\n        accuracy = np.mean(preds_list == target_list) * 100.\n        \n        #pred = output.cpu().data.numpy().argmax()\n        #qwk = cohen_kappa_score(pred, labels, weights='quadratic')\n    \n    return test_loss, accuracy, image_id, preds_list, target_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training parameters and t=0 inputs\nepochs = 3\nprint_every = 20\nsteps = 0\ntest_loss = 0\n\n# May the training begin!\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0\n    \n    for ii, (inputs, labels, image_id) in enumerate(train_loader):\n        steps += 1\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n       \n        outputs = model.forward(inputs)#.forward(inputs)\n        loss = criterion(outputs, labels)#.long())\n        loss.backward()\n        optimizer.step()\n    \n        \n        running_loss += loss.item()\n        \n        if steps % print_every == 0:\n            model.eval()\n            \n            train_accuracy=0.0\n            \n            with torch.no_grad():\n                valid_loss, accuracy, image_id,_,_ = validate_data_function(model, valid_loader, criterion)\n                train_accuracy = (outputs.sum(1).round() == labels.sum(1)).float().mean()*100.\n            \n            print(f\"Epoch: {epoch+1}/{epochs}..| \"\n                  f\"Train loss: {running_loss/print_every:.3f}..| \"\n                  f\"Train accuracy: {train_accuracy:.3f}..| \"\n                  f\"Validation loss: {valid_loss/print_every:.3f}..| \"                  \n                  f\"Validation accuracy: {accuracy:.3f}|\"\n                 )\n            \n            running_loss = 0\n            model.train()\n    \n    path = 'base_model.pth'\n    torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'classifier_state_dict': model._fc.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss\n            }, path)\n    \n    \n    model.cuda() # moving model to GPU for further training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    valid_loss, accuracy, image_id = validate_data_function(model, valid_loader, criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\n    \nwith torch.no_grad():\n    test_loss, accuracy, image_id = validate_data_function(model, test_loader, criterion)\n                \nprint(\"Test Accuracy: {}%\".format(accuracy)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}